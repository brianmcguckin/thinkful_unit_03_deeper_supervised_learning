{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ID3 Algorithm\n",
    "\n",
    "__ID3 (Iterative Dichotomizer 3):__ goes through every feature to find the most valuable attribute, then splits based on the attribute. Moves down the tree until it either has a pure class or has met a terminating condition\n",
    "\n",
    "__Requirements for ID3:__\n",
    "- outcomes must be binary\n",
    "- attributes must be categorical (and can have many categories)\n",
    "- categories must be known and countable\n",
    "\n",
    "__Shannon Entropy H:__ for simplicity, slightly transform definition to raise probability to -1, removing the negative sign\n",
    "\n",
    "<center>__Original__</center>\n",
    "$$H=-\\sum_{i=1}^n P(x_i)log_2P(x_i)$$\n",
    "<center>__Transformation__</center>\n",
    "$$H=\\sum_{i=1}^n P(x_i)log_2\\frac{1}{P(x_i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Entropy\n",
    "\n",
    "__Example:__ Let's say we have 20 students, and we're trying to classify them as male and female. The only attribute we have is whether their height is tall, medium, or short.\n",
    "\n",
    "__12 boys__\n",
    "- 4 tall\n",
    "- 6 medium\n",
    "- 2 short\n",
    "\n",
    "__8 girls__\n",
    "- 1 tall\n",
    "- 2 medium\n",
    "- 5 short\n",
    "\n",
    "What is the entropy, both before any rule is applied and then after applying a rule for being tall?\n",
    "\n",
    "The initial entropy is just the formula plugged in over both the possible classes of interest:\n",
    "\n",
    "$$ H = P(male)*log_2 \\frac{1}{P(male)} + P(female)*log_2 \\frac{1}{P(female)}  $$\n",
    "\n",
    "\n",
    "$$ = \\frac{12}{20}*log_2 \\frac{20}{12} + \\frac{8}{20}*log_2 \\frac{20}{8} = .971 $$\n",
    "\n",
    "What if we apply the rule _height = short_? We need to calculate the weighted average of the two entropies, one for the short students and one for the non-short students.\n",
    "\n",
    "$$ H(short) = P(male)*log_2 \\frac{1}{P(male)} + P(female)*log_2 \\frac{1}{P(female)}  $$\n",
    "\n",
    "$$ = \\frac{2}{7}*log_2 \\frac{7}{2} + \\frac{5}{7}*log_2 \\frac{7}{5} = .863 $$\n",
    "\n",
    "$$ H(not\\_short) = P(male)*log_2 \\frac{1}{P(male)} + P(female)*log_2 \\frac{1}{P(female)}  $$\n",
    "\n",
    "$$ = \\frac{10}{13}*log_2 \\frac{13}{10} + \\frac{3}{13}*log_2 \\frac{13}{3} = .779 $$\n",
    "\n",
    "Note that all the probabilities here are conditional on the criteria we're assuming (short or not short). Now the weighted average of the two is just:\n",
    "\n",
    "$$ P(short) * H(short) + P(not\\_short) * H(not\\_short) = \\frac{7}{20} * .863 + \\frac{13}{20} * .779 = .809 $$\n",
    "\n",
    "So our entropy from this question would go from .971 to .809. That's an improvement. Use the space below to calculate the entropy of the other criteria, for we asked whether the students were tall or medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule: height = medium\n",
      " 0.9245112497836532\n",
      "\n",
      "Rule: height = tall\n",
      " 0.9280757477080679\n"
     ]
    }
   ],
   "source": [
    "from math import log2\n",
    "\n",
    "#calculate entropy for tall and medium\n",
    "\n",
    "#medium\n",
    "H_med = (6/8) * (log2(8/6)) + (2/8) * (log2(8/2))\n",
    "H_not_med = (6/12) * log2(12/6) + (6/12) * (log2(12/6))\n",
    "H_med_w = (8/20) * H_med + (12/20) * H_not_med\n",
    "print('Rule: height = medium\\n',H_med_w)\n",
    "\n",
    "#tall\n",
    "H_tall = (4/5) * (log2(5/4)) + (1/5) * (log2(5/1))\n",
    "H_not_tall = (8/15) * (log2(15/8)) + (7/15) * (log2(15/7))\n",
    "H_tall_w = (5/20) * H_tall + (15/20) * H_not_tall\n",
    "print('\\nRule: height = tall\\n',H_tall_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which entropy offers the most information gain? Short"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudocoding the Algorithm\n",
    "\n",
    "__Pseudocoding:__ the process of writing the steps and logic to implement in code in normal language (as opposed to commands executable by programming languages); can be useful to chart out how to build an algorithm\n",
    "\n",
    "__Pseudocode for ID3:__ outcome is A or B, a<sub>i</sub> = attribute, v<sub>i</sub> = value of that attribute\n",
    "\n",
    "<pre>\n",
    "Algorithm(Observations, Outcome, Attributes)\n",
    "    Create a root node\n",
    "    If all observations are A, label root node A and return\n",
    "    If all observations are B, label root node B and return\n",
    "    If no attributes return the root note labeled with the most common outcome\n",
    "    Otherwise, start:\n",
    "        For each value v<sub>i</sub> of each attribute a<sub>i</sub>, calculate entropy\n",
    "        The attribute a<sub>i</sub> and value v<sub>i</sub> with the lowest entropy is the best rule\n",
    "        The attribute for this node is then a<sub>i</sub>\n",
    "            Split the tree to below based on the rule a<sub>i</sub> = v<sub>i</sub>\n",
    "            Observations<sub>v<sub>i</sub></sub> is the subset of observations with the value v<sub>i</sub>\n",
    "            If Observations<sub>v<sub>i</sub></sub> is empty cap with node labeled most common Outcome\n",
    "            Else at the new node start a subtree(Observations<sub>v<sub>i</sub></sub>, Target Outcome, Attributes -\n",
    "            {a<sub>i</sub>}) and repeat the algorithm\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
