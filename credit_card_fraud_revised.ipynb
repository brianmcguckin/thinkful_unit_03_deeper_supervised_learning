{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import imblearn\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class value counts:\n",
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n",
      "\n",
      "Percent fraud: 0.17304750013189596%\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv('creditcard.csv')\n",
    "print('Class value counts:')\n",
    "print(df_raw['Class'].value_counts())\n",
    "print('\\nPercent fraud: {}%'.format(\n",
    "    ((df_raw['Class']==1).sum()/(df_raw['Class']==0).sum())*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "- Dataset is huge and very imbalanced\n",
    "- Variables are already principle components, perform some feature selection\n",
    "- Address imbalance with under/oversampling techniques\n",
    "- Need to select train & test sets that won't undersample the minority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 kbest features:\n",
      "['V10', 'V12', 'V14', 'V16', 'V17']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X = df_raw.loc[:, ~df_raw.columns.isin(['Class'])] #data\n",
    "y = df_raw['Class'] #target\n",
    "\n",
    "k=5\n",
    "kbest = SelectKBest(f_classif, k=k) #instantiate\n",
    "kbest.fit(X, y)\n",
    "\n",
    "#unmask k features selected\n",
    "mask = kbest.get_support()\n",
    "k_features = []\n",
    "for bool, feature in zip(mask, X.columns):\n",
    "    if bool:\n",
    "        k_features.append(feature)\n",
    "print('{} kbest features:'.format(k))\n",
    "print(k_features)\n",
    "\n",
    "X_kbest = df_raw[k_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put k features and outcomes together\n",
    "df_kbest = pd.concat([X_kbest, df_raw['Class']], axis=1)\n",
    "\n",
    "#separate majority and minority classes\n",
    "df_class0 = df_kbest.loc[df_kbest['Class'] == 0]\n",
    "df_class1 = df_kbest.loc[df_kbest['Class'] == 1]\n",
    "\n",
    "#set new feature/target variables for each class for train_test_split\n",
    "X_0 = df_class0.drop(['Class'], axis=1)\n",
    "y_0 = pd.DataFrame(df_class0['Class'])\n",
    "X_1 = df_class1.drop(['Class'], axis=1)\n",
    "y_1 = pd.DataFrame(df_class1['Class'])\n",
    "\n",
    "#check df classes\n",
    "#print(df_class0['Class'].value_counts())\n",
    "#print(df_class1['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_raw fraud: 0.17304750013189596%\n",
      "y_train fraud: 0.1727837082109632%\n",
      "y_test fraud: 0.17410266781562705%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#majority class\n",
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(X_0,\n",
    "                                                        y_0,\n",
    "                                                        test_size=0.2)\n",
    "#minority class\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_1,\n",
    "                                                        y_1,\n",
    "                                                        test_size=0.2)\n",
    "#combine to create class proportional train & test sets\n",
    "X_train = pd.concat([X_train0, X_train1])\n",
    "X_test = pd.concat([X_test0, X_test1]) \n",
    "y_train = pd.concat([y_train0, y_train1])\n",
    "y_test = pd.concat([y_test0, y_test1])\n",
    "\n",
    "#check train & test class ratio against original data\n",
    "print('df_raw fraud: {}%'.format(\n",
    "    ((df_raw['Class']==1).sum()/(df_raw['Class']==0).sum())*100))\n",
    "print('y_train fraud: {}%'.format(\n",
    "    ((y_train['Class']==1).sum()/(y_train['Class']==0).sum())*100))\n",
    "print('y_test fraud: {}%'.format(\n",
    "    ((y_test['Class']==1).sum()/(y_test['Class']==0).sum())*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance\n",
    "SKLearn is lacking in this area, supplement with __imblearn's random sampling methods__\n",
    "- Cluster the records of the majority class\n",
    "- __Under-sample:__ remove records from each cluster, thus seeking to preserve information\n",
    "- __Over-sample:__ instead of creating exact copies of the minority class records, this introduces small variations into those copies, creating more diverse synthetic samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oversampled fraud: 50.0%\n",
      "786\n",
      "198\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#run random undersample on data\n",
    "rus = RandomUnderSampler()\n",
    "X_train_rus, y_train_rus = rus.fit_sample(X_train, y_train)\n",
    "X_test_rus, y_test_rus = rus.fit_sample(X_test, y_test)\n",
    "\n",
    "#check results\n",
    "print('oversampled fraud: {}%'.format(\n",
    "    len(y_train_rus[y_train_rus == 1]) / len(y_train_rus) * 100))\n",
    "print(len(y_train_rus))\n",
    "print(len(y_test_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename oversampled variables names for consistency\n",
    "X_train = X_train_rus\n",
    "y_train = y_train_rus\n",
    "X_test = X_test_rus\n",
    "y_test = y_test_rus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters:\n",
      " {'criterion': 'gini', 'max_features': 1, 'n_estimators': 50}\n",
      "\n",
      "Best score:\n",
      " 0.9351145038167938\n",
      "\n",
      "runtime:\n",
      " 0.8219620000000001 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#parameter search\n",
    "params = [{'n_estimators':[5, 10, 25, 50],\n",
    "           'criterion':['entropy','gini'],\n",
    "           'max_features':[1]}]\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "grid = GridSearchCV(estimator=rfc, param_grid=params)\n",
    "\n",
    "start_time = time.clock()\n",
    "grid.fit(X_train, y_train)\n",
    "print('\\nBest parameters:\\n', grid.best_params_)\n",
    "print('\\nBest score:\\n', grid.best_score_)\n",
    "print('\\nruntime:\\n',time.clock() - start_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=1, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train with params\n",
    "rfc = ensemble.RandomForestClassifier(criterion='gini',\n",
    "                                      max_features=1,\n",
    "                                      n_estimators=50)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To evaluate, calculate:__\n",
    "- __Confusion matrix:__ rows are actual, columns are prediction\n",
    "- __Type I Error (false positive):__ identify as 1 (fraud) but 0\n",
    "- __Type II Error (false negative):__ identify as 0 but 1\n",
    "- __Sensitivity (recall):__ percentage that 1 was correctly identified\n",
    "- __Specificity:__ percentage that 0 was correctly identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC train confusion matrix:\n",
      " [[393   0]\n",
      " [  0 393]]\n",
      "\n",
      "RFC train type i error:\n",
      " 0\n",
      "\n",
      "RFC train type ii error:\n",
      " 0\n",
      "\n",
      "RFC train sensitivity (recall):\n",
      " 1.0\n",
      "\n",
      "RFC train specificity:\n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#confusion matrix\n",
    "y_pred_rfc = rfc.predict(X_train)\n",
    "rfc_cm = confusion_matrix(y_train, y_pred_rfc)\n",
    "\n",
    "#error\n",
    "ti_rfc = rfc_cm[0,1]\n",
    "tii_rfc = rfc_cm[1,0]\n",
    "sens_rfc = rfc_cm[1,1] / (rfc_cm[1,0] + rfc_cm[1,1])\n",
    "spec_rfc = rfc_cm[0,0] / (rfc_cm[0,0] + rfc_cm[0,1])\n",
    "\n",
    "print('RFC train confusion matrix:\\n',rfc_cm)\n",
    "print('\\nRFC train type i error:\\n',ti_rfc)\n",
    "print('\\nRFC train type ii error:\\n',tii_rfc)\n",
    "print('\\nRFC train sensitivity (recall):\\n',sens_rfc)\n",
    "print('\\nRFC train specificity:\\n',spec_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC test confusion matrix:\n",
      " [[96  3]\n",
      " [12 87]]\n",
      "\n",
      "RFC test type i error:\n",
      " 3\n",
      "\n",
      "RFC test type ii error:\n",
      " 12\n",
      "\n",
      "RFC test sensitivity (recall):\n",
      " 0.8787878787878788\n",
      "\n",
      "RFC test specificity:\n",
      " 0.9696969696969697\n"
     ]
    }
   ],
   "source": [
    "#evaluate on test set\n",
    "#confusion matrix\n",
    "y_pred_rfc = rfc.predict(X_test)\n",
    "rfc_cm = confusion_matrix(y_test, y_pred_rfc)\n",
    "\n",
    "#error\n",
    "ti_rfc = rfc_cm[0,1]\n",
    "tii_rfc = rfc_cm[1,0]\n",
    "sens_rfc = rfc_cm[1,1] / (rfc_cm[1,0] + rfc_cm[1,1])\n",
    "spec_rfc = rfc_cm[0,0] / (rfc_cm[0,0] + rfc_cm[0,1])\n",
    "\n",
    "print('RFC test confusion matrix:\\n',rfc_cm)\n",
    "print('\\nRFC test type i error:\\n',ti_rfc)\n",
    "print('\\nRFC test type ii error:\\n',tii_rfc)\n",
    "print('\\nRFC test sensitivity (recall):\\n',sens_rfc)\n",
    "print('\\nRFC test specificity:\\n',spec_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Result:__ RFC is definitely overfitting. Not sure RFC is the best to use on data this imbalanced, undersampling left out a lot of class 0 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters:\n",
      " {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 250, 'subsample': 0.75}\n",
      "\n",
      "Best score:\n",
      " 0.9402035623409669\n",
      "\n",
      "runtime:\n",
      " 121.47475 seconds\n"
     ]
    }
   ],
   "source": [
    "#parameter search\n",
    "params = [{'loss':['deviance','exponential'],\n",
    "           'learning_rate':[0.01, 0.1, 1],\n",
    "           'n_estimators':[125, 250, 500],\n",
    "           'max_depth':[2, 3, 4],\n",
    "           'subsample':[0.25, 0.5, 0.75, 1]}]\n",
    "\n",
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "grid = GridSearchCV(estimator=gbc, param_grid=params)\n",
    "\n",
    "start_time = time.clock()\n",
    "grid.fit(X_train, y_train)\n",
    "print('\\nBest parameters:\\n', grid.best_params_)\n",
    "print('\\nBest score:\\n', grid.best_score_)\n",
    "print('\\nruntime:\\n',time.clock() - start_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.01, loss='exponential', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=250,\n",
       "              presort='auto', random_state=None, subsample=0.75, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train with best params\n",
    "gbc = ensemble.GradientBoostingClassifier(loss='exponential',\n",
    "                                          learning_rate=0.01,\n",
    "                                          n_estimators=250,\n",
    "                                          max_depth=3,\n",
    "                                          subsample=0.75)\n",
    "gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBC train confusion matrix:\n",
      " [[384   9]\n",
      " [ 30 363]]\n",
      "\n",
      "GBC train type i error:\n",
      " 9\n",
      "\n",
      "GBC train type ii error:\n",
      " 30\n",
      "\n",
      "GBC train sensitivity (recall):\n",
      " 0.9236641221374046\n",
      "\n",
      "GBC train specificity:\n",
      " 0.9770992366412213\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "y_pred_gbc = gbc.predict(X_train)\n",
    "gbc_cm = confusion_matrix(y_train, y_pred_gbc)\n",
    "\n",
    "#error\n",
    "ti_gbc = gbc_cm[0,1]\n",
    "tii_gbc = gbc_cm[1,0]\n",
    "sens_gbc = gbc_cm[1,1] / (gbc_cm[1,0] + gbc_cm[1,1])\n",
    "spec_gbc = gbc_cm[0,0] / (gbc_cm[0,0] + gbc_cm[0,1])\n",
    "\n",
    "print('GBC train confusion matrix:\\n',gbc_cm)\n",
    "print('\\nGBC train type i error:\\n',ti_gbc)\n",
    "print('\\nGBC train type ii error:\\n',tii_gbc)\n",
    "print('\\nGBC train sensitivity (recall):\\n',sens_gbc)\n",
    "print('\\nGBC train specificity:\\n',spec_gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBC test confusion matrix:\n",
      " [[99  0]\n",
      " [ 6 93]]\n",
      "\n",
      "GBC test type i error:\n",
      " 0\n",
      "\n",
      "GBC test type ii error:\n",
      " 6\n",
      "\n",
      "GBC test sensitivity (recall):\n",
      " 0.9393939393939394\n",
      "\n",
      "GBC test specificity:\n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "#evaluate clf_gbc on test set\n",
    "gbc.fit(X_test, y_test)\n",
    "\n",
    "#confusion matrix\n",
    "y_pred_gbc = gbc.predict(X_test)\n",
    "gbc_cm = confusion_matrix(y_test, y_pred_gbc)\n",
    "\n",
    "#error\n",
    "ti_gbc = gbc_cm[0,1]\n",
    "tii_gbc = gbc_cm[1,0]\n",
    "sens_gbc = gbc_cm[1,1] / (gbc_cm[1,0] + gbc_cm[1,1])\n",
    "spec_gbc = gbc_cm[0,0] / (gbc_cm[0,0] + gbc_cm[0,1])\n",
    "\n",
    "print('GBC test confusion matrix:\\n',gbc_cm)\n",
    "print('\\nGBC test type i error:\\n',ti_gbc)\n",
    "print('\\nGBC test type ii error:\\n',tii_gbc)\n",
    "print('\\nGBC test sensitivity (recall):\\n',sens_gbc)\n",
    "print('\\nGBC test specificity:\\n',spec_gbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Result:__ Better results than RFC, slightly higher test scores than train scores is of concern, could simply be due the size of undersampled dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters:\n",
      " {'C': 1, 'kernel': 'rbf'}\n",
      "\n",
      "Best score:\n",
      " 0.9325699745547074\n",
      "\n",
      "runtime:\n",
      " 0.26949100000001636 seconds\n"
     ]
    }
   ],
   "source": [
    "#parameter search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "params = [{'C':[0.01, 0.1, 1, 10],\n",
    "           'kernel':['rbf','linear','poly']}]\n",
    "\n",
    "svc = SVC()\n",
    "grid_svc = GridSearchCV(estimator=svc, param_grid=params)\n",
    "\n",
    "start_time = time.clock()\n",
    "grid_svc.fit(X_train, y_train)\n",
    "print('\\nBest parameters:\\n', grid_svc.best_params_)\n",
    "print('\\nBest score:\\n', grid_svc.best_score_)\n",
    "print('\\nruntime:\\n',time.clock() - start_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train with params\n",
    "svc = SVC(C=1,kernel='rbf')\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC train confusion matrix:\n",
      " [[385   8]\n",
      " [ 33 360]]\n",
      "\n",
      "SVC train type i error:\n",
      " 8\n",
      "\n",
      "SVC train type ii error:\n",
      " 33\n",
      "\n",
      "SVC train sensitivity (recall):\n",
      " 0.916030534351145\n",
      "\n",
      "SVC train specificity:\n",
      " 0.9796437659033079\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "y_pred_svc = svc.predict(X_train)\n",
    "svc_cm = confusion_matrix(y_train, y_pred_svc)\n",
    "\n",
    "#error\n",
    "ti_svc = svc_cm[0,1]\n",
    "tii_svc = svc_cm[1,0]\n",
    "sens_svc = svc_cm[1,1] / (svc_cm[1,0] + svc_cm[1,1])\n",
    "spec_svc = svc_cm[0,0] / (svc_cm[0,0] + svc_cm[0,1])\n",
    "\n",
    "print('SVC train confusion matrix:\\n',svc_cm)\n",
    "print('\\nSVC train type i error:\\n',ti_svc)\n",
    "print('\\nSVC train type ii error:\\n',tii_svc)\n",
    "print('\\nSVC train sensitivity (recall):\\n',sens_svc)\n",
    "print('\\nSVC train specificity:\\n',spec_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC test confusion matrix:\n",
      " [[94  5]\n",
      " [10 89]]\n",
      "\n",
      "SVC test type i error:\n",
      " 5\n",
      "\n",
      "SVC test type ii error:\n",
      " 10\n",
      "\n",
      "SVC test sensitivity (recall):\n",
      " 0.898989898989899\n",
      "\n",
      "SVC test specificity:\n",
      " 0.9494949494949495\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "svc_cm = confusion_matrix(y_test, y_pred_svc)\n",
    "\n",
    "#error\n",
    "ti_svc = svc_cm[0,1]\n",
    "tii_svc = svc_cm[1,0]\n",
    "sens_svc = svc_cm[1,1] / (svc_cm[1,0] + svc_cm[1,1])\n",
    "spec_svc = svc_cm[0,0] / (svc_cm[0,0] + svc_cm[0,1])\n",
    "\n",
    "print('SVC test confusion matrix:\\n',svc_cm)\n",
    "print('\\nSVC test type i error:\\n',ti_svc)\n",
    "print('\\nSVC test type ii error:\\n',tii_svc)\n",
    "print('\\nSVC test sensitivity (recall):\\n',sens_svc)\n",
    "print('\\nSVC test specificity:\\n',spec_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Result:__ most trustworthy results so far, with pretty high accuracy and some but not too much overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters:\n",
      " {'C': 0.1, 'fit_intercept': True, 'max_iter': 50, 'penalty': 'l1'}\n",
      "\n",
      "Best score:\n",
      " 0.9338422391857506\n",
      "\n",
      "runtime:\n",
      " 0.3899989999999889 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#parameter search\n",
    "params = [{'penalty':['l1','l2'],\n",
    "           'C':[0.01, 0.1, 1, 10],\n",
    "           'fit_intercept':[True, False],\n",
    "           'max_iter':[50,100,200]}]\n",
    "\n",
    "clf_lr = LogisticRegression()\n",
    "grid = GridSearchCV(estimator=clf_lr, param_grid=params)\n",
    "\n",
    "start_time = time.clock()\n",
    "grid.fit(X_train, y_train)\n",
    "print('\\nBest parameters:\\n', grid.best_params_)\n",
    "print('\\nBest score:\\n', grid.best_score_)\n",
    "print('\\nruntime:\\n',time.clock() - start_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=50, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "clf_lr = LogisticRegression(penalty='l1',\n",
    "                            C=0.1,\n",
    "                            fit_intercept=True,\n",
    "                            max_iter=50)\n",
    "clf_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC train confusion matrix:\n",
      " [[387   6]\n",
      " [ 48 345]]\n",
      "\n",
      "LR train type i error:\n",
      " 6\n",
      "\n",
      "LR train type ii error:\n",
      " 48\n",
      "\n",
      "LR train sensitivity (recall):\n",
      " 0.8778625954198473\n",
      "\n",
      "LR train specificity:\n",
      " 0.9847328244274809\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "y_pred_lr = clf_lr.predict(X_train)\n",
    "lr_cm = confusion_matrix(y_train, y_pred_lr)\n",
    "\n",
    "#error\n",
    "ti_lr = lr_cm[0,1]\n",
    "tii_lr = lr_cm[1,0]\n",
    "sens_lr = lr_cm[1,1] / (lr_cm[1,0] + lr_cm[1,1])\n",
    "spec_lr = lr_cm[0,0] / (lr_cm[0,0] + lr_cm[0,1])\n",
    "\n",
    "print('SVC train confusion matrix:\\n',lr_cm)\n",
    "print('\\nLR train type i error:\\n',ti_lr)\n",
    "print('\\nLR train type ii error:\\n',tii_lr)\n",
    "print('\\nLR train sensitivity (recall):\\n',sens_lr)\n",
    "print('\\nLR train specificity:\\n',spec_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC test confusion matrix:\n",
      " [[95  4]\n",
      " [11 88]]\n",
      "\n",
      "LR test type i error:\n",
      " 4\n",
      "\n",
      "LR test type ii error:\n",
      " 11\n",
      "\n",
      "LR test sensitivity (recall):\n",
      " 0.8888888888888888\n",
      "\n",
      "LR test specificity:\n",
      " 0.9595959595959596\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "y_pred_lr = clf_lr.predict(X_test)\n",
    "lr_cm = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "#error\n",
    "ti_lr = lr_cm[0,1]\n",
    "tii_lr = lr_cm[1,0]\n",
    "sens_lr = lr_cm[1,1] / (lr_cm[1,0] + lr_cm[1,1])\n",
    "spec_lr = lr_cm[0,0] / (lr_cm[0,0] + lr_cm[0,1])\n",
    "\n",
    "print('SVC test confusion matrix:\\n',lr_cm)\n",
    "print('\\nLR test type i error:\\n',ti_lr)\n",
    "print('\\nLR test type ii error:\\n',tii_lr)\n",
    "print('\\nLR test sensitivity (recall):\\n',sens_lr)\n",
    "print('\\nLR test specificity:\\n',spec_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Result:__ Recall results are a little fishy, similar results to SVC but I think SVC's are more reliable/trustworthy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
